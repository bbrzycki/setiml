{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from blimpy import read_header, Waterfall, Filterbank\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os, glob\n",
    "sys.path.append(\"../../setigen\")\n",
    "import setigen as stg\n",
    "\n",
    "tsamp = 1.0\n",
    "fch1 = 6095.214842353016\n",
    "df = -1.0e-06\n",
    "\n",
    "fchans = 1024\n",
    "tchans = 32\n",
    "\n",
    "fs = np.arange(fch1, fch1 + fchans*df, df)\n",
    "ts = np.arange(0, tchans*tsamp, tsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 17s 535ms/step - loss: 0.7606 - acc: 0.5045 - val_loss: 0.6867 - val_acc: 0.5078\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 16s 509ms/step - loss: 0.6923 - acc: 0.5439 - val_loss: 0.6456 - val_acc: 0.6536\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 16s 522ms/step - loss: 0.6794 - acc: 0.6227 - val_loss: 0.5943 - val_acc: 0.6953\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 15s 490ms/step - loss: 0.6418 - acc: 0.6531 - val_loss: 0.6276 - val_acc: 0.6380\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 19s 610ms/step - loss: 0.6214 - acc: 0.6648 - val_loss: 0.5719 - val_acc: 0.7422\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 18s 592ms/step - loss: 0.6103 - acc: 0.6703 - val_loss: 0.7239 - val_acc: 0.5859\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 19s 617ms/step - loss: 0.6201 - acc: 0.6682 - val_loss: 0.5772 - val_acc: 0.7448\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 17s 550ms/step - loss: 0.5942 - acc: 0.6932 - val_loss: 0.6290 - val_acc: 0.5651\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 19s 609ms/step - loss: 0.5616 - acc: 0.7001 - val_loss: 0.5347 - val_acc: 0.7031\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 19s 615ms/step - loss: 0.5677 - acc: 0.7159 - val_loss: 0.5383 - val_acc: 0.7292\n",
      "Saved model! Took 00h 02m 56.16s\n"
     ]
    }
   ],
   "source": [
    "# basic cnn training: 1\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, errno\n",
    "import time\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "def format_time(total):\n",
    "    h = int(np.floor(total / 3600.))\n",
    "    m = int(np.floor((total - 3600. * h) / 60.))\n",
    "    s = (total - 3600. * h - 60. * m)\n",
    "    return '%02dh %02dm %02.2fs' % (h, m, s)\n",
    "\n",
    "start = time.time()\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 1024\n",
    "\n",
    "VERSION = 'v1'\n",
    "\n",
    "dir = 'scintillated_small'\n",
    "\n",
    "train_data_dir = '/datax/scratch/bbrzycki/data/%s/train/' % (dir)\n",
    "validation_data_dir = '/datax/scratch/bbrzycki/data/%s/validation/' % (dir)\n",
    "nb_train_samples = 1000*2\n",
    "nb_validation_samples = 200*2\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model_dir = '/datax/scratch/bbrzycki/models/scintillated/'\n",
    "try:\n",
    "    os.makedirs(model_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "model.save_weights(model_dir + '%s_%s.h5' % ('scintillated', VERSION))\n",
    "\n",
    "end = time.time()\n",
    "print('Saved model! Took %s' % format_time(end - start))\n",
    "\n",
    "# at the end of 50 epochs: 31/31 - 16s 522ms/step\n",
    "# loss: 0.1979 - acc: 0.9289 - val_loss: 0.1578 - val_acc: 0.9479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 64s 2s/step - loss: 0.6983 - acc: 0.5453 - val_loss: 0.6848 - val_acc: 0.5365\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 59s 2s/step - loss: 0.7525 - acc: 0.6130 - val_loss: 0.5821 - val_acc: 0.7786\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 58s 2s/step - loss: 0.6336 - acc: 0.7030 - val_loss: 0.6319 - val_acc: 0.6198\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 59s 2s/step - loss: 0.5479 - acc: 0.7625 - val_loss: 0.4761 - val_acc: 0.7760\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 59s 2s/step - loss: 0.5122 - acc: 0.7651 - val_loss: 0.4957 - val_acc: 0.7891\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 60s 2s/step - loss: 0.4703 - acc: 0.7928 - val_loss: 0.4811 - val_acc: 0.7448\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 57s 2s/step - loss: 0.4265 - acc: 0.7913 - val_loss: 0.5377 - val_acc: 0.7682\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 59s 2s/step - loss: 0.3650 - acc: 0.8211 - val_loss: 0.3884 - val_acc: 0.8490\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 61s 2s/step - loss: 0.2948 - acc: 0.8720 - val_loss: 0.2607 - val_acc: 0.8594\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 57s 2s/step - loss: 0.2938 - acc: 0.8704 - val_loss: 0.2188 - val_acc: 0.9167\n",
      "Saved model! Took 00h 09m 55.02s\n"
     ]
    }
   ],
   "source": [
    "# basic cnn training: 2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, errno\n",
    "import time\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "def format_time(total):\n",
    "    h = int(np.floor(total / 3600.))\n",
    "    m = int(np.floor((total - 3600. * h) / 60.))\n",
    "    s = (total - 3600. * h - 60. * m)\n",
    "    return '%02dh %02dm %02.2fs' % (h, m, s)\n",
    "\n",
    "start = time.time()\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 64, 1024\n",
    "\n",
    "VERSION = 'v2'\n",
    "\n",
    "dir = 'scintillated_small'\n",
    "\n",
    "train_data_dir = '/datax/scratch/bbrzycki/data/%s/train/' % (dir)\n",
    "validation_data_dir = '/datax/scratch/bbrzycki/data/%s/validation/' % (dir)\n",
    "nb_train_samples = 1000*2\n",
    "nb_validation_samples = 200*2\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model_dir = '/datax/scratch/bbrzycki/models/scintillated/'\n",
    "try:\n",
    "    os.makedirs(model_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "model.save_weights(model_dir + '%s_%s.h5' % ('scintillated', VERSION))\n",
    "\n",
    "end = time.time()\n",
    "print('Saved model! Took %s' % format_time(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 126, 1022, 32)     896       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 126, 1022, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 63, 511, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 61, 509, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 61, 509, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 30, 254, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 252, 64)       18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 252, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 126, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 124, 64)       36928     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 12, 124, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 6, 62, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 60, 128)        73856     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4, 60, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 2, 30, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               983168    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,122,850\n",
      "Trainable params: 1,122,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 20s 634ms/step - loss: 0.7037 - acc: 0.5261 - val_loss: 0.6637 - val_acc: 0.6354\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 0.6828 - acc: 0.6008 - val_loss: 0.6945 - val_acc: 0.5391\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 19s 599ms/step - loss: 0.6334 - acc: 0.6527 - val_loss: 0.5735 - val_acc: 0.6875\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 19s 598ms/step - loss: 0.5963 - acc: 0.7047 - val_loss: 0.5345 - val_acc: 0.6979\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 20s 630ms/step - loss: 0.5998 - acc: 0.7131 - val_loss: 0.5198 - val_acc: 0.7552\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 17s 554ms/step - loss: 0.5258 - acc: 0.7434 - val_loss: 0.5153 - val_acc: 0.7526\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 19s 615ms/step - loss: 0.5481 - acc: 0.7340 - val_loss: 0.5007 - val_acc: 0.7474\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 18s 595ms/step - loss: 0.5170 - acc: 0.7633 - val_loss: 0.4715 - val_acc: 0.7917\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 18s 595ms/step - loss: 0.4926 - acc: 0.7646 - val_loss: 0.4482 - val_acc: 0.7995\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 19s 629ms/step - loss: 0.4606 - acc: 0.7787 - val_loss: 0.5815 - val_acc: 0.7318\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 20s 637ms/step - loss: 0.4596 - acc: 0.7883 - val_loss: 0.5868 - val_acc: 0.7682\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 18s 578ms/step - loss: 0.4457 - acc: 0.7923 - val_loss: 0.3766 - val_acc: 0.8568\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 19s 621ms/step - loss: 0.4297 - acc: 0.7928 - val_loss: 0.4934 - val_acc: 0.8828\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 19s 597ms/step - loss: 0.4110 - acc: 0.8201 - val_loss: 0.4298 - val_acc: 0.8229\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 20s 629ms/step - loss: 0.4025 - acc: 0.8357 - val_loss: 0.3987 - val_acc: 0.8542\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 18s 578ms/step - loss: 0.3820 - acc: 0.8339 - val_loss: 0.3785 - val_acc: 0.8672\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 18s 576ms/step - loss: 0.3811 - acc: 0.8402 - val_loss: 0.3193 - val_acc: 0.8854\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 21s 664ms/step - loss: 0.3344 - acc: 0.8695 - val_loss: 0.3614 - val_acc: 0.8568\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 15s 498ms/step - loss: 0.3145 - acc: 0.8771 - val_loss: 0.3540 - val_acc: 0.8828\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 16s 524ms/step - loss: 0.3205 - acc: 0.8755 - val_loss: 0.3041 - val_acc: 0.8828\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 20s 639ms/step - loss: 0.2929 - acc: 0.8896 - val_loss: 0.4278 - val_acc: 0.8672\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 17s 551ms/step - loss: 0.2982 - acc: 0.8826 - val_loss: 0.4704 - val_acc: 0.8594\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 0.3215 - acc: 0.8860 - val_loss: 0.3058 - val_acc: 0.8984\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 16s 522ms/step - loss: 0.3105 - acc: 0.8842 - val_loss: 0.2694 - val_acc: 0.8984\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 17s 555ms/step - loss: 0.2594 - acc: 0.9088 - val_loss: 0.2457 - val_acc: 0.9089\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 17s 562ms/step - loss: 0.2585 - acc: 0.8922 - val_loss: 0.2881 - val_acc: 0.8854\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 18s 567ms/step - loss: 0.2840 - acc: 0.8901 - val_loss: 0.2832 - val_acc: 0.9062\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 17s 537ms/step - loss: 0.2578 - acc: 0.9049 - val_loss: 0.3037 - val_acc: 0.8828\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.2480 - acc: 0.9028 - val_loss: 0.2828 - val_acc: 0.8906\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 18s 577ms/step - loss: 0.2498 - acc: 0.9078 - val_loss: 0.3147 - val_acc: 0.8984\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 19s 616ms/step - loss: 0.2278 - acc: 0.9129 - val_loss: 0.3101 - val_acc: 0.8958\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 17s 538ms/step - loss: 0.2470 - acc: 0.9078 - val_loss: 0.2117 - val_acc: 0.9401\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 17s 542ms/step - loss: 0.2196 - acc: 0.9208 - val_loss: 0.1874 - val_acc: 0.9375\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 17s 540ms/step - loss: 0.2172 - acc: 0.9203 - val_loss: 0.2041 - val_acc: 0.9297\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 17s 543ms/step - loss: 0.2197 - acc: 0.9219 - val_loss: 0.1686 - val_acc: 0.9505\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 16s 511ms/step - loss: 0.2197 - acc: 0.9258 - val_loss: 0.2368 - val_acc: 0.9349\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 17s 549ms/step - loss: 0.2089 - acc: 0.9258 - val_loss: 0.2700 - val_acc: 0.9245\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 17s 544ms/step - loss: 0.2232 - acc: 0.9219 - val_loss: 0.2662 - val_acc: 0.9219\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 18s 594ms/step - loss: 0.2183 - acc: 0.9284 - val_loss: 0.2184 - val_acc: 0.9219\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 16s 508ms/step - loss: 0.2053 - acc: 0.9314 - val_loss: 0.2114 - val_acc: 0.9323\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 16s 509ms/step - loss: 0.1818 - acc: 0.9359 - val_loss: 0.1756 - val_acc: 0.9323\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 17s 537ms/step - loss: 0.1643 - acc: 0.9415 - val_loss: 0.1600 - val_acc: 0.9349\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 16s 518ms/step - loss: 0.2021 - acc: 0.9311 - val_loss: 0.2771 - val_acc: 0.9349\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 15s 489ms/step - loss: 0.1773 - acc: 0.9381 - val_loss: 0.2453 - val_acc: 0.9219\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 18s 571ms/step - loss: 0.1930 - acc: 0.9340 - val_loss: 0.2355 - val_acc: 0.9297\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.1618 - acc: 0.9375 - val_loss: 0.1909 - val_acc: 0.9479\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 15s 487ms/step - loss: 0.1649 - acc: 0.9415 - val_loss: 0.2146 - val_acc: 0.9219\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 15s 493ms/step - loss: 0.1601 - acc: 0.9461 - val_loss: 0.2175 - val_acc: 0.9219\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 16s 512ms/step - loss: 0.1937 - acc: 0.9390 - val_loss: 0.2450 - val_acc: 0.8984\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 18s 590ms/step - loss: 0.1655 - acc: 0.9375 - val_loss: 0.2844 - val_acc: 0.9323\n",
      "Saved model! Took 00h 14m 38.71s\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 30, 1022, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 30, 1022, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 15, 511, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 509, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 13, 509, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 254, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 4, 252, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 4, 252, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 2, 126, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,065,186\n",
      "Trainable params: 1,065,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# basic cnn training: 3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, errno\n",
    "import time\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "def format_time(total):\n",
    "    h = int(np.floor(total / 3600.))\n",
    "    m = int(np.floor((total - 3600. * h) / 60.))\n",
    "    s = (total - 3600. * h - 60. * m)\n",
    "    return '%02dh %02dm %02.2fs' % (h, m, s)\n",
    "\n",
    "start = time.time()\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 1024\n",
    "\n",
    "VERSION = 'v3'\n",
    "\n",
    "dir = 'scintillated_small'\n",
    "\n",
    "train_data_dir = '/datax/scratch/bbrzycki/data/%s/train/' % (dir)\n",
    "validation_data_dir = '/datax/scratch/bbrzycki/data/%s/validation/' % (dir)\n",
    "nb_train_samples = 1000*2\n",
    "nb_validation_samples = 200*2\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model_dir = '/datax/scratch/bbrzycki/models/scintillated/'\n",
    "try:\n",
    "    os.makedirs(model_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "model.save_weights(model_dir + '%s_%s.h5' % ('scintillated', VERSION))\n",
    "\n",
    "end = time.time()\n",
    "print('Saved model! Took %s' % format_time(end - start))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "62/62 [==============================] - 18s 284ms/step - loss: 0.9901 - acc: 0.5131 - val_loss: 0.6923 - val_acc: 0.4974\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 17s 270ms/step - loss: 0.6966 - acc: 0.5045 - val_loss: 0.7293 - val_acc: 0.4974\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 17s 267ms/step - loss: 0.6889 - acc: 0.5837 - val_loss: 0.6361 - val_acc: 0.5911\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 17s 281ms/step - loss: 0.6778 - acc: 0.6225 - val_loss: 0.5879 - val_acc: 0.6615\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 17s 271ms/step - loss: 0.6178 - acc: 0.6552 - val_loss: 0.5360 - val_acc: 0.7240\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 19s 310ms/step - loss: 0.6380 - acc: 0.6583 - val_loss: 0.5152 - val_acc: 0.7630\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 16s 261ms/step - loss: 0.6385 - acc: 0.7263 - val_loss: 0.5062 - val_acc: 0.7839\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 20s 323ms/step - loss: 0.5946 - acc: 0.7168 - val_loss: 0.5891 - val_acc: 0.7839\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 18s 284ms/step - loss: 0.5830 - acc: 0.7147 - val_loss: 0.5331 - val_acc: 0.7865\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 16s 262ms/step - loss: 0.5247 - acc: 0.7500 - val_loss: 0.8737 - val_acc: 0.5260\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 17s 273ms/step - loss: 0.5330 - acc: 0.7510 - val_loss: 0.4084 - val_acc: 0.8255\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 17s 281ms/step - loss: 0.5265 - acc: 0.7480 - val_loss: 0.4197 - val_acc: 0.8333\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 19s 304ms/step - loss: 0.4810 - acc: 0.7868 - val_loss: 0.5904 - val_acc: 0.7630\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 17s 270ms/step - loss: 0.4760 - acc: 0.7767 - val_loss: 0.5577 - val_acc: 0.8411\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 17s 266ms/step - loss: 0.4622 - acc: 0.7989 - val_loss: 0.3891 - val_acc: 0.8568\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 16s 266ms/step - loss: 0.4373 - acc: 0.8175 - val_loss: 0.3220 - val_acc: 0.8958\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 16s 260ms/step - loss: 0.4327 - acc: 0.8216 - val_loss: 0.2950 - val_acc: 0.8620\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 18s 283ms/step - loss: 0.4409 - acc: 0.8367 - val_loss: 0.7138 - val_acc: 0.8568\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 19s 303ms/step - loss: 0.4049 - acc: 0.8402 - val_loss: 0.3569 - val_acc: 0.8620\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 18s 289ms/step - loss: 0.4027 - acc: 0.8463 - val_loss: 0.2785 - val_acc: 0.8828\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 16s 257ms/step - loss: 0.3529 - acc: 0.8629 - val_loss: 0.2804 - val_acc: 0.9062\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 16s 258ms/step - loss: 0.3869 - acc: 0.8589 - val_loss: 0.2841 - val_acc: 0.8802\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 16s 264ms/step - loss: 0.3652 - acc: 0.8553 - val_loss: 0.2815 - val_acc: 0.8854\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 18s 292ms/step - loss: 0.3356 - acc: 0.8594 - val_loss: 0.2280 - val_acc: 0.9245\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 16s 258ms/step - loss: 0.3483 - acc: 0.8700 - val_loss: 0.2671 - val_acc: 0.9010\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 18s 285ms/step - loss: 0.3192 - acc: 0.8780 - val_loss: 0.2339 - val_acc: 0.9349\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 17s 271ms/step - loss: 0.3488 - acc: 0.8785 - val_loss: 0.2160 - val_acc: 0.9323\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 18s 286ms/step - loss: 0.2929 - acc: 0.8911 - val_loss: 0.1928 - val_acc: 0.9323\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 19s 307ms/step - loss: 0.3162 - acc: 0.8886 - val_loss: 0.2527 - val_acc: 0.9427\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 19s 302ms/step - loss: 0.3038 - acc: 0.8876 - val_loss: 0.1731 - val_acc: 0.9453\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 16s 258ms/step - loss: 0.2892 - acc: 0.8896 - val_loss: 0.3349 - val_acc: 0.8620\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 19s 310ms/step - loss: 0.2895 - acc: 0.8967 - val_loss: 0.1887 - val_acc: 0.9349\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 19s 310ms/step - loss: 0.2807 - acc: 0.9047 - val_loss: 0.9118 - val_acc: 0.7969\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 16s 265ms/step - loss: 0.2711 - acc: 0.9108 - val_loss: 0.1881 - val_acc: 0.9323\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 19s 303ms/step - loss: 0.3027 - acc: 0.9073 - val_loss: 0.1986 - val_acc: 0.9349\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 16s 263ms/step - loss: 0.2705 - acc: 0.9002 - val_loss: 0.1849 - val_acc: 0.9297\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 17s 270ms/step - loss: 0.2641 - acc: 0.9128 - val_loss: 0.2088 - val_acc: 0.9219\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 20s 315ms/step - loss: 0.3449 - acc: 0.9012 - val_loss: 0.1782 - val_acc: 0.9479\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 16s 266ms/step - loss: 0.2872 - acc: 0.9002 - val_loss: 0.1471 - val_acc: 0.9479\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 16s 262ms/step - loss: 0.2220 - acc: 0.9259 - val_loss: 0.2378 - val_acc: 0.9167\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 16s 263ms/step - loss: 0.2779 - acc: 0.9022 - val_loss: 0.1946 - val_acc: 0.9349\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 18s 295ms/step - loss: 0.2642 - acc: 0.9113 - val_loss: 0.2756 - val_acc: 0.9401\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 16s 257ms/step - loss: 0.2261 - acc: 0.9244 - val_loss: 0.1883 - val_acc: 0.9323\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 16s 261ms/step - loss: 0.2461 - acc: 0.9133 - val_loss: 0.1488 - val_acc: 0.9583\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 16s 259ms/step - loss: 0.2473 - acc: 0.9214 - val_loss: 0.1755 - val_acc: 0.9505\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 16s 252ms/step - loss: 0.2628 - acc: 0.9183 - val_loss: 0.1635 - val_acc: 0.9531\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 16s 261ms/step - loss: 0.2144 - acc: 0.9355 - val_loss: 0.1862 - val_acc: 0.9401\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 16s 256ms/step - loss: 0.2274 - acc: 0.9158 - val_loss: 0.1319 - val_acc: 0.9531\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 16s 258ms/step - loss: 0.1962 - acc: 0.9254 - val_loss: 0.2565 - val_acc: 0.9505\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 16s 258ms/step - loss: 0.2228 - acc: 0.9330 - val_loss: 0.1373 - val_acc: 0.9583\n",
      "Saved model! Took 00h 14m 18.70s\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 28, 1020, 32)      2432      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 28, 1020, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 24, 1016, 32)      25632     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 24, 1016, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 12, 508, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 504, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 8, 504, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 4, 252, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64512)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4128832   \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 4,208,698\n",
      "Trainable params: 4,208,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# basic cnn training: 4\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, errno\n",
    "import time\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "def format_time(total):\n",
    "    h = int(np.floor(total / 3600.))\n",
    "    m = int(np.floor((total - 3600. * h) / 60.))\n",
    "    s = (total - 3600. * h - 60. * m)\n",
    "    return '%02dh %02dm %02.2fs' % (h, m, s)\n",
    "\n",
    "start = time.time()\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 1024\n",
    "\n",
    "VERSION = 'v4'\n",
    "\n",
    "dir = 'scintillated_small'\n",
    "\n",
    "train_data_dir = '/datax/scratch/bbrzycki/data/%s/train/' % (dir)\n",
    "validation_data_dir = '/datax/scratch/bbrzycki/data/%s/validation/' % (dir)\n",
    "nb_train_samples = 1000*2\n",
    "nb_validation_samples = 200*2\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model_dir = '/datax/scratch/bbrzycki/models/scintillated/'\n",
    "try:\n",
    "    os.makedirs(model_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "model.save_weights(model_dir + '%s_%s.h5' % ('scintillated', VERSION))\n",
    "\n",
    "end = time.time()\n",
    "print('Saved model! Took %s' % format_time(end - start))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
